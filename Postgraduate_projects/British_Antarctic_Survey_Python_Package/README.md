# DELPHI: Automatic Detection of Laser Points in Benthic Imagery

## Description

**DELPHI** (Detection of Laser Points in Huge image collections using Iterative learning) is a Python package developed in collaboration with the British Antarctic Survey, based on the methodology introduced by Timm Schoening.

The DELPHI package enables researchers to train and apply a laser point detection pipeline to benthic imagery. By providing paths to annotated laser point images and corresponding training images, users can initiate the training process. Once trained, the model can then be used to detect laser points in unlabelled (unseen) imagery.

## Table of Contents

- [Repository Structure](#repository-structure)
- [Installation](#installation)
- [Data Availability](#data-availability)
- [Usage](#usage)
- [License](#license)
- [Documentation](#documentation)

## Repository Structure

Below is a summary of the contents of this repository:

### `DELPHI/`

Contains the main Python package implementation. The core functionality is implemented in `LPdetection.py`.

### `jobs/`

SLURM job scripts designed for running large-scale experiments on CSD3 (the University of Cambridge’s HPC cluster). These jobs were used to generate the results presented in the accompanying report.

### `results/`

Each subdirectory in the results/ folder corresponds to a specific subsection of the report. Only lightweight CSV files have been pushed to the repository—these can be visualized using the plotting.ipynb notebook to recreate figures from the report.

Large outputs generated by the job scripts (e.g. interactive Plotly 3D HTML plots, and images of failed/successful predictions) were not pushed to the repository due to size constraints. However, they can be reproduced by running the corresponding scripts locally or on CSD3.

### `scripts/`

Contains full pipeline scripts associated with each job in the `jobs/` directory. These scripts implement training and detection loops. For example, `baseline_t1.py`, `baseline_t2.py`, and `combined_t1t2.py` run the pipeline with increasing training set sizes to replicate experiments from the DELPHI paper.

These scripts are designed to be run on CSD3 and are not intended for local execution.

### `t1.ipynb` and `t2.ipynb`

Simplified versions of the larger scripts, designed to be run locally. These notebooks:

- Perform a single train–test split using the default ratio
- Run the entire DELPHI pipeline
- Include inline visualisations at key stages

These notebooks are useful for inspecting intermediate outputs and verifying the detection pipeline.

### `tutorial/`

This directory provides a user-focused tutorial for applying DELPHI to custom datasets. It is intended for researchers who want to use DELPHI on their own images rather than replicate the results in the report.

### `additional_information/`

Contains supplementary materials that were not included in the report, such as preliminary data analysis and visualisations (e.g., depth plots). These were useful for understanding the structure and content of the dataset during early exploration.

## **Installation**

### **Installation into CSD3** 

1. Clone this repository:

```bash
git clone https://gitlab.developers.cam.ac.uk/phy/data-intensive-science-mphil/assessments/projects/jn492_v2.git
```

2. Clean the Environment

```bash
    module purge
    module load miniconda3
```

2. Create the Virtual Environment in the repository

```bash
cd jn492_v2
python -m venv delphienv
source delphienv/bin/activate
```

3. Install the required dependencies

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

### **Installation for local usage** 

1. Clone this repository:

```bash
git clone https://gitlab.developers.cam.ac.uk/phy/data-intensive-science-mphil/assessments/projects/jn492_v2.git
```

2. Create a Virtual Environment in the repository

```bash
cd jn492_v2
python3 -m venv delphienv
source delphienv/bin/activate
```

3. Install the required dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

4. Install the package

```bash
pip install .
```

## **Data Availability**

The dataset used with this package was provided by the British Antarctic Survey and can be downloaded from the following Google Drive link:

https://drive.google.com/drive/folders/1UsbCb_UEwd69wk5rZZqkOBadR9I5JIR6?usp=sharing

This link contains two main folders:

- `Replicate_thesis_locally/`  
- `Replicate_thesis_CSD3/`

Depending on your use case, follow the instructions below

### **Data for CSD3 Usage**  

If you wish to replicate all the results in the report, it is recommended to run the scripts in parallel in CSD3 as the full processing loops are computationally expensive. Hence, separate datasets are needed for each experiment. Navigate to `Replicate_thesis_CSD3/` and download all six folders: data_1, data_2, data_3, data_4, data_5, data_6. You may need to download each data folder separately due to google's downloading size limits. Place them in the **parent directory** of your repository (e.g., `jn492_v2/`), alongside your code folder. 

### **Data for local usage**

 If you prefer not to run the full processing loops with CSD3 scripts, you can test the package locally in Jupyter using a minimal dataset. In this case, navigate to `Replicate_thesis_locally/` and download `data`.Place them in the **parent directory** of your repository (e.g., `jn492_v2/`), alongside your code folder.

---

If there are access issues, please contact: [jn492@cam.ac.uk](mailto:jn492@cam.ac.uk)  

Alternatively, if you are a researcher using this, then you can use any image and annotations you may have. Please see section 2.2 'Preprocessing of dataset' of the thesis to view the formatting requirements of the images and requirements needed. 

## **Usage**

### Replicating ALL Thesis Results

To reproduce the **full set of experiments**, I recommend running the jobs on **CSD3**, as the experiments involve loops of training and detection with varying training set sizes. These are computationally intensive and can take a long time to run locally.

The following job scripts in the `jobs/` directory were used to generate the results in my thesis:

- `baseline_t1.sh` and `baseline_t2.sh`: Figures 9, 13, 14, 15 (Baseline experiments)
- `mc_t1.sh` and `mc_t2.sh`: Figure 16 (Monte Carlo simulations)
- `kfold_t1.sh` and `kfold_t1.sh`: Figure 17 (K-Fold cross-validation) 
- `morph_t1.sh` and `morph_t1.sh`: Figure 18 (Morphological opening tuning)
- `radius_t1.sh` and `radius_t2.sh`: Figures 19 and 20 (Radius tuning experiments)
- `combined_t1t2.sh`: Figure 21 (Combining substrate types)

Submit each job using SLURM by running. The job names correspond to each python script, which is stored under the directorry `scripts/`:

   ```bash
   sbatch jobs/job_name.sh
   ```
### Replicating Lightweight Thesis Results

To only run one iteration of the training size, download the `Replicate_thesis_locally` data folder into the `jn492_v2` repository, and use the notebooks `t1.ipynb` and `t2.ipynb`. to run. It should generate figures 11 and 12 and the appendix results to show you how each step it trains and detects in the pipeline.

Make sure you confirgure the Jupyter environment is using the correct virtual environment kernel before executing the notebook cells.

```bash
python -m ipykernel install --user --name=delphienv --display-name "DELPHI (delphienv)"
```

From here, open either the `t1.ipynb` or `t2.ipynb` notebooks, click on `Select Kernel`, Navigate to `Jupyter Kernels` and select DELHPI (venv).

### Using DELPHI as a researcher 

If you are using this package as a researcher, then you can import your own data into the parent directory, and then run the tutorial.ipynb notenbook Make sure you confirgure the Jupyter environment is using the correct virtual environment kernel before executing the notebook cells.

```bash
python -m ipykernel install --user --name=delphienv --display-name "DELPHI (delphienv)"
```

Then, locate the `#CHANGEME` comments in the `tutorial.ipynb` notebook to replace the following with your own file paths:
   - Path to **training images** and **laser point annotations**
   - Path to **unlabelled test images** and optionally **laser point annotations** if you want to evaluate performance using F1-score, precision, recall. 

## **License**

This project is protected under the MIT License.

## **Documentation**

Documentation is generated using **Sphinx** based on the Python docstrings.

To view the documentation locally:

```bash
cd DELPHI/docs
make html
open build/html/index.html 
```
