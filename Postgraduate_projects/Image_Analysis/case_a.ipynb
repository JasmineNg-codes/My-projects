{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c14ef4-4de5-476d-ac2a-7f59ff00f230",
   "metadata": {},
   "source": [
    "# Exercise 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2806ff98-84f2-4ed0-b2ce-652e24e22ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Define model for case 'a'\n",
    "case = 'a'\n",
    "num_classes = 10 \n",
    "num_epochs = 500\n",
    "\n",
    "if case == 'a':\n",
    "    inputs, n_hidden0, n_hidden1, out = 784*3, 64, 16, 10\n",
    "    ckpt_pth = 'best_model_NN.pth'\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(inputs, n_hidden0, bias=True), \n",
    "        nn.Tanh(),\n",
    "        nn.Linear(n_hidden0, n_hidden1, bias=True),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(n_hidden1, out, bias=True),\n",
    "        nn.Softmax(dim=1)\n",
    "    ).to('cuda')\n",
    "elif case == 'b':\n",
    "    ckpt_pth = 'best_model_CNN.pth'\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "    model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "    model = model.to('cuda')\n",
    "else:\n",
    "    raise ValueError('Case choice is invalid')\n",
    "\n",
    "model.train()\n",
    "\n",
    "#load data\n",
    "dev_path = './data/0_development_data.pkl'\n",
    "test_path = './data/0_test_data.pkl'\n",
    "\n",
    "with open(dev_path, 'rb') as f:\n",
    "    devel_data = pickle.load(f)\n",
    "\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "#combine\n",
    "combined_imgs = devel_data[0] + test_data[0]\n",
    "combined_labels = [int(i[0].split('/')[-2]) for i in combined_imgs]\n",
    "\n",
    "#split the train and test\n",
    "train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(\n",
    "    combined_imgs, combined_labels, test_size=0.25, stratify=combined_labels, random_state=42)\n",
    "\n",
    "#split the train and validation\n",
    "val_imgs, test_imgs, val_labels, test_labels = train_test_split(\n",
    "    temp_imgs, temp_labels, test_size=0.4, stratify=temp_labels, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_imgs)}, Validation: {len(val_imgs)}, Test: {len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b50f5450-95ef-4f9f-995a-47244d3adb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, labels, transform=None):\n",
    "        self.image_list = image_list\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if case == 'a':\n",
    "            image = self.image_list[idx].astype(float)\n",
    "            image /= 255.0\n",
    "            image -= np.sum(np.sum(image, 0), 0) / (image.shape[0] * image.shape[1])\n",
    "        elif case == 'b':\n",
    "            img_tmp = self.image_list[idx]\n",
    "            image = preprocess(Image.fromarray(img_tmp))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if case == 'a':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "train_array_list = [i[1] for i in train_imgs]\n",
    "val_array_list = [i[1] for i in val_imgs]\n",
    "test_array_list = [i[1] for i in test_imgs]\n",
    "\n",
    "dataset_train = CustomDataset(train_array_list, train_labels, transform=None)\n",
    "dataset_val = CustomDataset(val_array_list, val_labels, transform=None)\n",
    "dataset_test = CustomDataset(test_array_list, test_labels, transform=None)\n",
    "\n",
    "batch_size = 32\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdbbda5d-29c2-4698-8a56-e570ef1ded48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 482.42it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 751.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 1.4833602984987857, Val loss: 1.4919023401469083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 473.16it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 754.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 1.4803156834605256, Val loss: 1.4933049356321433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 483.84it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 757.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 1.4766990638431445, Val loss: 1.4865819132436735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 482.79it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 1.4747128562724336, Val loss: 1.4862191970587502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 484.50it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 755.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train loss: 1.4724069246767502, Val loss: 1.4849313870751748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 483.54it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 750.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train loss: 1.4713787235387552, Val loss: 1.489074838922379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 479.98it/s]\n",
      "100%|██████████| 329/329 [00:01<00:00, 183.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train loss: 1.471195677493481, Val loss: 1.4852214692936117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 361.67it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 738.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train loss: 1.4711558373141072, Val loss: 1.4820141285023791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 462.10it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 737.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train loss: 1.4698161256349558, Val loss: 1.4883903370077487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.86it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 737.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train loss: 1.468535166380978, Val loss: 1.4815568315221908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.28it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 738.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train loss: 1.4678967390379283, Val loss: 1.480916760612766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.79it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 739.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train loss: 1.4692315033503942, Val loss: 1.4820133545478427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.46it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 735.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train loss: 1.4676182208452544, Val loss: 1.484737014335702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.97it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 738.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train loss: 1.4685658455619697, Val loss: 1.4811377162991324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.80it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 739.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train loss: 1.4676379806002584, Val loss: 1.4818147022311086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.93it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 739.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train loss: 1.4673447148778156, Val loss: 1.4821851941952227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.38it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 738.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train loss: 1.4664753389213585, Val loss: 1.4803088291075455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 475.89it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 730.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train loss: 1.4669296060289656, Val loss: 1.4800791791144838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 472.28it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train loss: 1.4664943877686845, Val loss: 1.4799080565345324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 479.52it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 744.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train loss: 1.4659537689301743, Val loss: 1.4808744347928868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.61it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 744.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train loss: 1.466612387573103, Val loss: 1.4794182505651086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 477.16it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train loss: 1.4666648175578711, Val loss: 1.4783940177558041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 476.84it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train loss: 1.4657494394974868, Val loss: 1.478183537268711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.36it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train loss: 1.465164792573923, Val loss: 1.4788499871285854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 477.42it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 742.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train loss: 1.4652407937499166, Val loss: 1.4783583470028585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.38it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train loss: 1.464950050264144, Val loss: 1.4777205439686414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.45it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 740.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train loss: 1.4648097188277085, Val loss: 1.4790284662623536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.63it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 743.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train loss: 1.4663040029241683, Val loss: 1.4809010485385328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 477.96it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 741.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train loss: 1.4663963147572108, Val loss: 1.4803774936583267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.90it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 735.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train loss: 1.4662104486332113, Val loss: 1.4788206214238082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 479.49it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 742.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train loss: 1.4655148185857523, Val loss: 1.4802744678450934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 479.97it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 746.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train loss: 1.465321468002528, Val loss: 1.4796846412960156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:01<00:00, 184.40it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 742.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train loss: 1.4656198292880074, Val loss: 1.4791077676152748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 477.90it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 744.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train loss: 1.4656779592160396, Val loss: 1.4836738605992048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 477.20it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 742.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train loss: 1.4660280073305032, Val loss: 1.480588198070468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329/329 [00:00<00:00, 478.46it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 739.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Early Stopping ------------\n",
      "Epoch 36, Train loss: 1.464792055561912, Val loss: 1.4787404895915812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "early_stopping_patience = 10\n",
    "\n",
    "best_val_loss = 10000.0\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss, running_val_loss = 0.0, 0.0\n",
    "    model.train()\n",
    "    for inputs_, labels_ in tqdm(dataloader_train):\n",
    "        \n",
    "        if case == 'a': inputs_ = torch.reshape(inputs_, (inputs_.shape[0], -1))\n",
    "        inputs_, labels_ = inputs_.to(torch.float).to('cuda'), labels_.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_)\n",
    "        loss = criterion(outputs, labels_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs_val, labels_val in tqdm(dataloader_val):\n",
    "            if case == 'a': inputs_val = torch.reshape(inputs_val, (inputs_val.shape[0], -1))\n",
    "            inputs_val, labels_val = inputs_val.to(torch.float).to('cuda'), labels_val.to('cuda')\n",
    "            outputs_val = model(inputs_val)\n",
    "            val_loss = criterion(outputs_val, labels_val)\n",
    "            running_val_loss += val_loss.item()\n",
    "            \n",
    "    epoch_val_loss = running_val_loss/len(dataloader_val)\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        early_stopping_counter = 0\n",
    "        best_val_loss = float(epoch_val_loss)\n",
    "        torch.save(model.state_dict(), ckpt_pth)\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter==early_stopping_patience:\n",
    "            print('-------- Early Stopping ------------')\n",
    "            print(f'Epoch {epoch+1}, Train loss: {running_loss/len(dataloader_train)}, Val loss: {running_val_loss/len(dataloader_val)}')\n",
    "            break\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {running_loss/len(dataloader_train)}, Val loss: {epoch_val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b91e72f-1667-4dbe-9b54-f9cb84542824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2352, out_features=64, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the train data\n",
    "model.load_state_dict(torch.load(ckpt_pth, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23a0db36-5b2b-44f9-8210-f94641d522ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def get_predictions(input_batch, model):\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b11e70b-44ba-485b-a5a6-f8dd5c6009cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:00<00:00, 695.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "preds_list = []\n",
    "batch_size = 64\n",
    "with torch.no_grad():\n",
    "    for inputs_test, _ in tqdm(dataloader_test):\n",
    "        if case == 'a': inputs_test = torch.reshape(inputs_test, (inputs_test.shape[0], -1))\n",
    "        inputs_test = inputs_test.to(torch.float).to('cuda')\n",
    "        preds_list.append(get_predictions(inputs_test, model).cpu().numpy())\n",
    "final_preds = np.argmax(np.reshape(np.vstack(preds_list), (-1,10)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e192ffc-2e00-4a8e-83c2-cb8727bf7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all interesting metrics\n",
    "def multiclass_metrics(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Compute per-class accuracy, sensitivity (recall), specificity, and precision.\n",
    "    \n",
    "    y_true, y_pred : array-like of shape (n_samples,)\n",
    "    labels         : list of class labels, e.g. [0,1,...,9]\n",
    "    \"\"\"\n",
    "    # Compute the full confusion matrix once\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    # cm[i, j] is count of true class i predicted as class j\n",
    "    \n",
    "    # Prepare containers\n",
    "    metrics = {\n",
    "        \"class\": [],\n",
    "        \"accuracy\": [],\n",
    "        \"sensitivity (recall)\": [],\n",
    "        \"specificity\": [],\n",
    "        \"precision\": []\n",
    "    }\n",
    "    \n",
    "    # Total samples\n",
    "    total = cm.sum()\n",
    "    \n",
    "    for idx, cls in enumerate(labels):\n",
    "        TP = cm[idx, idx]\n",
    "        FN = cm[idx, :].sum() - TP\n",
    "        FP = cm[:, idx].sum() - TP\n",
    "        TN = total - TP - FP - FN\n",
    "        \n",
    "        # Per-class metrics\n",
    "        acc = (TP + TN) / total\n",
    "        sens = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        spec = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "        prec = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        \n",
    "        metrics[\"class\"].append(cls)\n",
    "        metrics[\"accuracy\"].append(acc)\n",
    "        metrics[\"sensitivity (recall)\"].append(sens)\n",
    "        metrics[\"specificity\"].append(spec)\n",
    "        metrics[\"precision\"].append(prec)\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ef7ecc0-0e98-47cd-9276-cc4e865c7c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity (recall)</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998048</td>\n",
       "      <td>0.988471</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.993989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994287</td>\n",
       "      <td>0.972236</td>\n",
       "      <td>0.996722</td>\n",
       "      <td>0.970377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.997663</td>\n",
       "      <td>0.979714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996286</td>\n",
       "      <td>0.994106</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.968421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.901633</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.892855</td>\n",
       "      <td>0.478604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.990817</td>\n",
       "      <td>0.996937</td>\n",
       "      <td>0.972486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995096</td>\n",
       "      <td>0.970014</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>0.982965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.993334</td>\n",
       "      <td>0.959646</td>\n",
       "      <td>0.996943</td>\n",
       "      <td>0.971116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995144</td>\n",
       "      <td>0.976122</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>0.975191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  sensitivity (recall)  specificity  precision\n",
       "class                                                        \n",
       "0      0.901062              0.000000     0.999366   0.000000\n",
       "1      0.998048              0.988471     0.999250   0.993989\n",
       "2      0.994287              0.972236     0.996722   0.970377\n",
       "3      0.995477              0.976562     0.997663   0.979714\n",
       "4      0.996286              0.994106     0.996520   0.968421\n",
       "5      0.901633              0.989989     0.892855   0.478604\n",
       "6      0.996334              0.990817     0.996937   0.972486\n",
       "7      0.995096              0.970014     0.998032   0.982965\n",
       "8      0.993334              0.959646     0.996943   0.971116\n",
       "9      0.995144              0.976122     0.997250   0.975191"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performance\n",
    "report_df = multiclass_metrics(test_labels, final_preds, np.arange(10).tolist()).set_index('class')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#how many train, validation, test coutns there are\n",
    "print(\"Train:\\n\", pd.Series(train_labels).value_counts().sort_index())\n",
    "print(\"Validation:\\n\", pd.Series(val_labels).value_counts().sort_index())\n",
    "print(\"Test:\\n\", pd.Series(test_labels).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "\n",
    "train_counts = pd.Series(train_labels).value_counts().sort_index()\n",
    "val_counts = pd.Series(val_labels).value_counts().sort_index()\n",
    "test_counts = pd.Series(test_labels).value_counts().sort_index()\n",
    "\n",
    "#make a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Class': train_counts.index,\n",
    "    'Train': train_counts.values,\n",
    "    'Validation': val_counts.values,\n",
    "    'Test': test_counts.values\n",
    "})\n",
    "\n",
    "# Plot\n",
    "x = np.arange(len(df['Class']))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - width, df['Train'], width, label='Train')\n",
    "plt.bar(x, df['Validation'], width, label='Validation')\n",
    "plt.bar(x + width, df['Test'], width, label='Test')\n",
    "\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('Class Distribution Across Train, Validation, and Test Sets')\n",
    "plt.xticks(x, df['Class'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and download\n",
    "plt.savefig('class_distribution.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Optional: download image from Colab\n",
    "files.download('class_distribution.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vetct_env",
   "language": "python",
   "name": "vetct_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
